{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWk6yUpzIhYO",
        "outputId": "53376a7c-ceba-459f-c082-974536c62fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from resampy) (2.0.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.11/dist-packages (from resampy) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.53->resampy) (0.43.0)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install resampy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yflm5UvFWh-r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import resampy\n",
        "import librosa\n",
        "import os\n",
        "import soundfile as sf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_sWqCP7IOl"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "7CRFdTfa_Kjl",
        "outputId": "3885c8a0-36dc-4e20-9edd-2a4ed95536e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dd80e28e-d35b-4ade-a742-43693e38e0e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dd80e28e-d35b-4ade-a742-43693e38e0e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"hassanimtiaz5980\",\"key\":\"2499cf051667a70b38dce37247fc5147\"}'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vjRjphOcKwR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.rename(\"kaggle (1).json\", \"kaggle.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gSvkf0EMBJU2"
      },
      "outputs": [],
      "source": [
        "# Move kaggle.json to the correct location\n",
        "!mkdir -p ~/.kaggle ! # making the .kaggle folder\n",
        "!cp kaggle.json ~/.kaggle/  #  put your secret key file kagle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json   #  locking it so only i can use this file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nhc6MVwB-8Q",
        "outputId": "14082565-958d-4f2b-82c8-e740ba5b1774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading ravdess-emotional-speech-audio.zip to /content\n",
            " 92% 393M/429M [00:00<00:00, 505MB/s]\n",
            "100% 429M/429M [00:00<00:00, 452MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the RAVDESS dataset using Kaggle API\n",
        "!kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nRdjv0kbFpx2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('ravdess-emotional-speech-audio.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('ravdess')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87IE3XAJC_l3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for root, _, files in os.walk('ravdess'):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            print(os.path.join(root, file))\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAOXOqUTMYCW"
      },
      "source": [
        "data_dir=os.path.join(\"content\",\"ravdess\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WsP-cMTXMmoU"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URW2ESTlO9tc",
        "outputId": "3edbbec4-9d90-48ad-c137-2f318123978a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actor_01  Actor_06  Actor_11  Actor_16\tActor_21\n",
            "Actor_02  Actor_07  Actor_12  Actor_17\tActor_22\n",
            "Actor_03  Actor_08  Actor_13  Actor_18\tActor_23\n",
            "Actor_04  Actor_09  Actor_14  Actor_19\tActor_24\n",
            "Actor_05  Actor_10  Actor_15  Actor_20\taudio_speech_actors_01-24\n"
          ]
        }
      ],
      "source": [
        "!ls /content/ravdess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfWpFHBQMj7V",
        "outputId": "f5368a6e-6308-45b8-974f-6be66048b2a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_dir class: <class 'str'>\n",
            "Data directory: /content/ravdess\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_dir=os.path.join(\"/content/ravdess\")\n",
        "\n",
        "\n",
        "print(\"data_dir class:\", type(data_dir))\n",
        "print(\"Data directory:\", data_dir)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEkYXSEzLjxm",
        "outputId": "3fbe83e7-ac2c-4da1-a706-6eba389ad695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will read data from  /content/ravdess\n"
          ]
        }
      ],
      "source": [
        "class_dir=os.listdir(data_dir)\n",
        "print(\"Will read data from \",data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KX6GRMlEz8m",
        "outputId": "3293d619-e8ff-4715-c8a4-8fd5cffc153e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 24 actors in the dataset.\n",
            "Actor directories: ['Actor_17', 'Actor_21', 'Actor_24', 'Actor_22', 'Actor_05', 'Actor_11', 'Actor_04', 'Actor_19', 'Actor_18', 'Actor_23', 'Actor_13', 'Actor_15', 'Actor_16', 'Actor_07', 'Actor_14', 'Actor_01', 'Actor_02', 'Actor_20', 'Actor_08', 'Actor_03', 'Actor_10', 'Actor_06', 'Actor_09', 'Actor_12']\n"
          ]
        }
      ],
      "source": [
        "actor_dir=[d for d in class_dir if d.startswith(\"Actor_\") and os.path.isdir(os.path.join(data_dir,d))]\n",
        "\n",
        "print(\"There are\", len(actor_dir), \"actors in the dataset.\")\n",
        "print(\"Actor directories:\", actor_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "qmHatyZ9VGv1",
        "outputId": "acc6982a-3a42-4b50-a68d-3eaeccba7e51"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2IAAAE8CAYAAACitAI8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU0dJREFUeJzt3Xd4U2X7B/BvkjZJd+mmpWxomQVaKFRkVqYgioD8VKbyvrygYHFQRIaouFgKgspygCIyVARk77LKLKMgs7R0QOneyfn9URuIXUlJzkna7+e6cknOec45d3pqkzvP89yPTBAEAURERERERCQaudQBEBERERER1TRMxIiIiIiIiETGRIyIiIiIiEhkTMSIiIiIiIhExkSMiIiIiIhIZEzEiIiIiIiIRMZEjIiIiIiISGRMxIiIiIiIiETGRIyIiIiIiEhkTMSIiIjM6IcffkBgYCBsbW3h6uoqdThERGQhmIgREZHF++WXXyCTybBp06ZS+4KCgiCTybB3795S++rWrYuwsDAxQizT5cuXMWrUKDRq1AjffvstvvnmG8liISIiy8JEjIiILF7nzp0BAIcOHdLbnpGRgZiYGNjY2ODw4cN6++Li4hAXF6c7Vgr79u2DVqvFokWLMGrUKAwdOlSyWIiIyLIwESMiIovn6+uLBg0alErEoqKiIAgChgwZUmpfyXMpE7Hk5GQAMOmQxJycHJOdi4iIpMNEjIiIrELnzp1x+vRp5Obm6rYdPnwYLVq0QN++fXH06FFotVq9fTKZDE888QRWrVqFHj16wMvLCyqVCs2bN8fSpUv1zv/000+jYcOGZV67U6dOCAkJ0dv2448/Ijg4GHZ2dnBzc8MLL7yAuLg43f769etj5syZAABPT0/IZDLMmjVLt/+rr75CixYtoFKp4OvriwkTJiAtLU3vGt26dUPLli0RHR2NLl26wN7eHtOmTcPNmzchk8nw+eefY8mSJWjYsCHs7e3Rq1cvxMXFQRAEzJkzB3Xq1IGdnR2eeeYZpKamGvXzJiIi82IiRkREVqFz584oLCzEsWPHdNsOHz6MsLAwhIWFIT09HTExMXr7AgMD4e7ujqVLl6JevXqYNm0a5s2bB39/f/zvf//DkiVLdO2HDRuGGzdu4MSJE3rXvXXrFo4ePYoXXnhBt+3DDz/EiBEj0KRJE8yfPx+TJ0/G7t270aVLF10ytXDhQjz77LMAgKVLl+KHH37Ac889BwCYNWsWJkyYAF9fX8ybNw+DBw/G119/jV69eqGwsFDv+vfv30ffvn3Rpk0bLFy4EN27d9ftW7NmDb766iu89tprmDJlCvbv34+hQ4di+vTp2L59O9555x2MGzcOf/zxB958883HvANERGRSAhERkRW4cOGCAECYM2eOIAiCUFhYKDg4OAjfffedIAiC4O3tLSxZskQQBEHIyMgQFAqF8OqrrwqCIAg5OTmlzte7d2+hYcOGuufp6emCSqUSpkyZotfu008/FWQymXDr1i1BEATh5s2bgkKhED788EO9dufPnxdsbGz0ts+cOVMAIKSkpOi2JScnC0qlUujVq5eg0Wh02xcvXiwAEFauXKnb1rVrVwGAsGzZMr1r3bhxQwAgeHp6CmlpabrtkZGRAgAhKChIKCws1G0fPny4oFQqhby8vNI/WCIikgR7xIiIyCo0a9YM7u7uurlfZ8+eRXZ2tq4qYlhYmK5gR1RUFDQajW5+mJ2dne486enpuHfvHrp27Yrr168jPT0dAODs7Iy+ffvil19+gSAIuvbr1q1Dx44dUbduXQDAxo0bodVqMXToUNy7d0/38PHxQZMmTcqs3vioXbt2oaCgAJMnT4Zc/vBt+NVXX4WzszP+/PNPvfYqlQqjR48u81xDhgyBi4uL7nloaCgA4KWXXoKNjY3e9oKCAsTHx1cYGxERiYeJGBERWQWZTIawsDDdXLDDhw/Dy8sLjRs3BqCfiJX8tyQRO3z4MMLDw+Hg4ABXV1d4enpi2rRpAKBLxIDi4YlxcXGIiooCAFy7dg3R0dEYNmyYrs3Vq1chCAKaNGkCT09PvcelS5d0BTrKc+vWLQBAQECA3nalUomGDRvq9pfw8/ODUqks81wlyWGJkqTM39+/zO0PHjyoMDYiIhKPTeVNiIiILEPnzp3xxx9/4Pz587r5YSXCwsLw1ltvIT4+HocOHYKvry8aNmyIa9euoWfPnggMDMT8+fPh7+8PpVKJrVu3YsGCBXoFPgYMGAB7e3v88ssvCAsLwy+//AK5XI4hQ4bo2mi1WshkMmzbtg0KhaJUjI6OjiZ9zY/25v1bWdevaPujPX1ERCQtJmJERGQ1Hl1P7PDhw5g8ebJuX3BwMFQqFfbt24djx46hX79+AIA//vgD+fn5+P333/V6kMoaQujg4ICnn34a69evx/z587Fu3To8+eST8PX11bVp1KgRBEFAgwYN0LRpU6NfQ7169QAAsbGxelUaCwoKcOPGDYSHhxt9TiIisj4cmkhERFYjJCQEarUaa9asQXx8vF6PmEqlQrt27bBkyRJkZ2frkraS3qFHe4PS09OxatWqMq8xbNgwJCQkYPny5Th79qzesEQAeO6556BQKDB79uxSPUyCIOD+/fsVvobw8HAolUp88cUXesevWLEC6enp6N+/vwE/CSIisnbsESMiIquhVCrRvn17HDx4ECqVCsHBwXr7w8LCMG/ePAAPe8969eoFpVKJAQMG4D//+Q+ysrLw7bffwsvLC3fv3i11jX79+sHJyQlvvvkmFAoFBg8erLe/UaNG+OCDDxAZGYmbN29i0KBBcHJywo0bN7Bp0yaMGzeuwlLxnp6eiIyMxOzZs9GnTx8MHDgQsbGx+Oqrr9C+fXu89NJLj/tjIiIiK8AeMSIisiolCVbJUMRHPfHEEwAAJycnBAUFASguivHrr79CJpPhzTffxLJlyzBu3DhMmjSpzPOr1WoMHDgQmZmZ6N69O7y8vEq1mTp1KjZs2AC5XI7Zs2fjzTffxO+//45evXph4MCBlb6GWbNmYfHixbh9+zbeeOMN/PLLLxg3bhx27NgBW1tbo34eRERknWQCZ+4SERERERGJij1iREREREREImMiRkREREREJDImYkRERERERCJjIkZERERERCQyJmJEREREREQiYyJGREREREQkMi7obAJarRYJCQlwcnKCTCaTOhwiIiIiIpKIIAjIzMyEr68v5PLy+72YiJlAQkIC/P39pQ6DiIiIiIgsRFxcHOrUqVPufiZiJuDk5ASg+Ift7OwscTRERERERCSVjIwM+Pv763KE8jARM4GS4YjOzs5MxIiIiIiIqNIpSyzWQUREREREJDImYkRERERERCJjIkZERERERCQyJmJEREREREQiYyJGREREREQkMiZiREREREREIrO6RGzJkiWoX78+1Go1QkNDcfz48Qrbr1+/HoGBgVCr1WjVqhW2bt1abtv//ve/kMlkWLhwoYmjJiIiIiIiesiqErF169YhIiICM2fOxKlTpxAUFITevXsjOTm5zPZHjhzB8OHDMXbsWJw+fRqDBg3CoEGDEBMTU6rtpk2bcPToUfj6+pr7ZRBRDXb+TjpCP9qFu+m5UodCREREErKqRGz+/Pl49dVXMXr0aDRv3hzLli2Dvb09Vq5cWWb7RYsWoU+fPnjrrbfQrFkzzJkzB+3atcPixYv12sXHx+O1117DmjVrYGtrK8ZLIaIaam9sMpIy8nE5MVPqUIiIiEhCVpOIFRQUIDo6GuHh4bptcrkc4eHhiIqKKvOYqKgovfYA0Lt3b732Wq0WL7/8Mt566y20aNHCoFjy8/ORkZGh9yAiIiIiIjKU1SRi9+7dg0ajgbe3t952b29vJCYmlnlMYmJipe0/+eQT2NjY4PXXXzc4lrlz58LFxUX38Pf3N+KVEFFNk1+kwboTt1Go0UodisW7lpKF7PwiqcMgIiIyO6tJxMwhOjoaixYtwurVqyGTyQw+LjIyEunp6bpHXFycGaMkImu3PSYR72w4jz2XH85nPRuXhu0xifjfmmgmHo/oOW8/pm8uPY+XiIiourGROgBDeXh4QKFQICkpSW97UlISfHx8yjzGx8enwvYHDx5EcnIy6tatq9uv0WgwZcoULFy4EDdv3izzvCqVCiqV6jFeDRHVJBl5xYnWV3v/Rm6hBgCwcNdV3f6hIf7oFuAlSWyWaFvMXSwY1kbqMIiIiMzKanrElEolgoODsXv3bt02rVaL3bt3o1OnTmUe06lTJ732ALBz505d+5dffhnnzp3DmTNndA9fX1+89dZb+Ouvv8z3YoioRjp7Jx1XkrJKbbeRW82fYiIiIjIRq+kRA4CIiAiMHDkSISEh6NChAxYuXIjs7GyMHj0aADBixAj4+flh7ty5AIBJkyaha9eumDdvHvr374+ff/4ZJ0+exDfffAMAcHd3h7u7u941bG1t4ePjg4CAAHFfHBERERER1RhWlYgNGzYMKSkpmDFjBhITE9GmTRts375dV5Dj9u3bkD/yzXJYWBjWrl2L6dOnY9q0aWjSpAk2b96Mli1bSvUSiIiIiIiIIBMEQZA6CGuXkZEBFxcXpKenw9nZWepwiMjC/HD0Ft6roADFj2ND0bmJh4gRWa76U/8EAHg7q7BtUhe4OSgljoiIiMg4huYGnJhARGRGl+5m4GxcmtRhWJ2kjHzcup8tdRhERERmY1VDE4mIrM3zS48gu0AjdRhERERkYdgjRkRkRkzCiIiIqCxMxIiIiIiIiETGRIyIiIiIiEhkTMSIiIiIiIhExkSMiIgskpPaVuoQiIiIzIZVE4mISHKbTt/Bj1G3pQ6DiIhINEzEiIhIcm+sOyt1CERERKLi0EQiIiIiIiKRMREjIiIiIiISGRMxIiIiIiIikTERIyIiIiIiEhkTMSIiicUmZeJaSpbUYRAREZGImIgREUlszpaLeH7pEanDICIiIhExESMisgAPcgqlDoGIiIhExESMiIiIiIhIZEzEiIiIiIiIRMZEjIiIiIiISGRMxIiIiIiIiERmI3UARETVkVYrYM3x21KHQURERBaKPWJERGZw8W4G3tscI3UYREREZKGYiBERmUGhRit1CFbvz3N3se5E6V7F9JxCdP98H07dfiBBVERERKbBRIyIiCzSgl1X8M6G8wCA6FsPMOmn0xAEAbdTc3DjXjY2nYqXOEIiIqKq4xwxIiKyeB/8eRGnb6ehd0sfpGTmSx0OERHRY2MiRkREFi+3QAMA+N+aUxJHQkREZBocmkhERERERCQyJmJEREREREQiYyJGREREREQkMiZiREQW4u1fzyIjr1DqMCwOlwIgIqLqiIkYEZGF+OXkHey5lGzy8+YVanA3Pdfk5xVLk3e34XJiptRhSEYQBAiCoHt+MSEDyZl5EkZERESmwKqJREQWRPvIB25TeWfDOfx2JgE3P+5v8nOT+b396zmk5RTCyc4GXk5qLNt/DcH1amHD+DCpQyMiosfARIyIqJr77UyC1CGYxQ9Hb+H9Z1pAJpNJHYpZrY++U2pb9K0HEkRCRESmxKGJRERktTRa0/cgWgvBDL2nREQkHiZiRERktbLyi6QOQTJ9Fh7Ewl1XpA6DiIiqiIkYEZEZqGwUUodQSvStVKRk5ksdRikJaVUvJFKTO4VikzKxcNdVqcMgIqIqYiJGRGQGShvL+/M6eGkUIn45g+0xdy0mIbvzIAdhH++ROgyrtvbYbdy8ly11GEREZCTL+6RARERmc/DqPfz3x1OY/ccFqUMBADzI5rppj2vapvN4Z8M5qcMgIiIjsWoiEVENFGsh63I5qCxvCKelSEzPw4GrKQa1vXmfPWJERNaGPWJERGaQXYOLSBijupeefxxztlzE278a3tM1+/cL2B5z14wRERGRKVldIrZkyRLUr18farUaoaGhOH78eIXt169fj8DAQKjVarRq1Qpbt27V7SssLMQ777yDVq1awcHBAb6+vhgxYgQSEqrnmjtEJJ6qLsy89XyiiSMha/XnecOTqqSMfKw6chP//fGUGSMiIiJTsqpEbN26dYiIiMDMmTNx6tQpBAUFoXfv3khOTi6z/ZEjRzB8+HCMHTsWp0+fxqBBgzBo0CDExMQAAHJycnDq1Cm89957OHXqFDZu3IjY2FgMHDhQzJdFRKRz5No9qUOgRxRptLiekiV1GEREVA1ZVSI2f/58vPrqqxg9ejSaN2+OZcuWwd7eHitXriyz/aJFi9CnTx+89dZbaNasGebMmYN27dph8eLFAAAXFxfs3LkTQ4cORUBAADp27IjFixcjOjoat2/fFvOlERGRBVpx6AZ6zNuP4zdScSYuTepwiIioGrGaRKygoADR0dEIDw/XbZPL5QgPD0dUVFSZx0RFRem1B4DevXuX2x4A0tPTIZPJ4OrqWm6b/Px8ZGRk6D2IiExBKwjIL9KY/TrX72Vj6b5r0Gpr8EJcBoi+9QAAMPTrKAxacljiaIiIqDqxmkTs3r170Gg08Pb21tvu7e2NxMSy51QkJiYa1T4vLw/vvPMOhg8fDmdn53JjmTt3LlxcXHQPf39/I18NEVV3VU1v8gq16LvooEljKYtGK+CT7ZdxKZFfJBEREUnBahIxcyssLMTQoUMhCAKWLl1aYdvIyEikp6frHnFxcSJFSUTWYsHOK1U+9nqKeKXItVrRLkUimb8jlnMNiYisgNUkYh4eHlAoFEhKStLbnpSUBB8fnzKP8fHxMah9SRJ269Yt7Ny5s8LeMABQqVRwdnbWexARlfjtTDwOXuUHYZLGF3v+xsS1p6UOg4iIKmE1iZhSqURwcDB2796t26bVarF792506tSpzGM6deqk1x4Adu7cqde+JAm7evUqdu3aBXd3d/O8ACKqMYxZ+4nIHFKzC6QOgYiIKmE1iRgARERE4Ntvv8V3332HS5cuYfz48cjOzsbo0aMBACNGjEBkZKSu/aRJk7B9+3bMmzcPly9fxqxZs3Dy5ElMnDgRQHES9vzzz+PkyZNYs2YNNBoNEhMTkZiYiIICvokRUdXkF3G8n1g2nLpjtnMfvX4ft1NzzHZ+IiKq2WykDsAYw4YNQ0pKCmbMmIHExES0adMG27dv1xXkuH37NuTyh7llWFgY1q5di+nTp2PatGlo0qQJNm/ejJYtWwIA4uPj8fvvvwMA2rRpo3etvXv3olu3bqK8LiIicxGjAqOUPvjzEoa194eT2tak580t0OCFb46a9JyG+iHqJg7/ff+xz7M95i76tKxtgoiIiMgcrCoRA4CJEyfqerT+bd++faW2DRkyBEOGDCmzff369SEILN1MRKblqLJBVn6R1GHg4NUUvLzieIVtCjTWn6iZowK/xoj3hoNXUxC58Tx2RXSF2lbx2Nd+77cLj30OANgWk1gtE7H4tFwIgoA6teylDoWI6LFY1dBEIiIy3PEbqZW2+ePsXREiqd5+iLqFOw9ykZlXZFFf7v12JgF7LydLHYbJPb/0CAYvPSJ1GEREj42JGBFRNZWQlldpm4zcQhEiqRlWHLqB7p/vg1YrIKdA+h5RABj3w8nHOj49pxDv/HoOGXmF2HM5CXmF0veg3k3PQ1JGvtRhEBE9NiZiRETVlCGFLG7cz8a5O2nmD6YMcak5uJhQfRaUXrb/Gm7ez8HY704geM4uqcMBABRqHq+HblvMXaw7GYfFe/7GmNUn8dPx2yaKzHiLdl3B8oPXdc/j03Kr1e8PEdU8VjdHjIiITOf07TQMXHwYNz/uL/q1R6w8jhv3xFu82hR+PHoLgT5O+DX6DiKeagovZzV2XNRfr3JvbIpE0ZleyVy5zLzintM7D3JFu3ahRgsZgDlbLkIuk2HVkZt6+0evOo4rSVmS/O4SEZkCEzEiIoJGK0Ahl4l6TWtLwgBg+uYY3b81WgGfDQmSMBrxSLEkw/BvjsLVXoldl5LK3H8lKavcY7Pyi5CaVYC67izoQUSWi0MTiYjIqsvcSzW00pjKitauZG6YVsTXfPLWg3KTsEddSEjH4j1X9ba9tf4suny211yhERGZBBMxIiKyattjEiW57pWkzAr3/xB1E9M3nRcpGvOSyYp7S13sTLtemym8/es5fL7jit62bRL9ThARGYOJGBGRiVnCGmJkfsmVVO5777cL+PGYdMUtTKGkAyw9x3KrayZl6FcH1ZpjYTkiIjNgIkZEREweq6CWvVLqEMzO7p8Fqs0xfzCvUIPcAv0hsc8sPoRl+68ZdZ70f5ZgKNIUz2NjGkZE1oKJGBERoQZNd6pUanYBbt/PqbSdrY24xU2kYGtT/DFh/xXTV4J8ecUxDPs6Sm/b2Tvp+HjbZaPOU6dWcUEOdoQRkbVhIkZEZIHuZYm7YG2RFX+KXWPi4X/jvj+Jfl8cNOk5qbQTNx/gXHy6yc4Xk5COzp/sQWJG5QuZExFZgiolYmlpaVi+fDkiIyORmpoKADh16hTi4+NNGhwRUU0V8sEuXK2kGIQpZXNoos7JWw8ManchIQNNp28zczTSShXpC4GLCRlIfiSBir6VavQ5dl9Kwp0HuTgXl6bblpjOpIyILJfR64idO3cO4eHhcHFxwc2bN/Hqq6/Czc0NGzduxO3bt/H999+bI04iohrnTloumng7GX2cVivg5ZXHjDpG5CXEqgVBAAokWF9LTCVDE83t3z2Qg5dGldOycrmFD+edLdp9FXOfa1XlcxERmZPRf2EjIiIwatQoXL16FWq1Wre9X79+OHDggEmDIyKqyZxURn9XBqB4mOHhv++bOBrT+ve6T1RzZOcXlSrSYQpO6uLS+o8WFhF7iC8RkTGMfpc/ceIEvv7661Lb/fz8kJjIdTuIiEylZO0mY1W2vpUl+Pe6T4/rekoWGno6mvScBNxNKz2077cz8Qht4A4fF3UZR1Ru6NdRumqMABCXWnlhlIrcuJet9/yXk3G6f2u1AlKzC+DmUP0rXBKR9TG6R0ylUiEjI6PU9itXrsDT09MkQRERWbOq9mT927/XRzLU2uPWvXZVVfSYt1/qEMo1Z8tFjF19Qvc8OTMPl+6Wfh+1RIv3/l1q26Sfz+C932KqfM4LCRl68/Ce/epwlc/1qOspWQCg1xu8+3Iy/u/boyY5PxGRqRmdiA0cOBDvv/8+CguL1+2QyWS4ffs23nnnHQwePNjkARIR1VRTfjlbaZuRK4/jz3N39bZZein6kvWeTE2w0Be+4tAN7L6crHs+8MvD6LvoIC7dzcCKQzckjKxiZf08F+4qHlJ69pGCGI/rXlaBSc7zy8k7ZW6/nGj5PcREVDMZnYjNmzcPWVlZ8PLyQm5uLrp27YrGjRvDyckJH374oTliJCKyKqZKB3ILNZUO29p/JQUzHqN3oqpO3kxFTBVLj5urVP4vJ+OqHJMYBEGAVivoyqu/tPwY5my5qNufnluIdzedlyo8PefupKH17B3l7q/qsEQiInrI6PEzLi4u2LlzJw4dOoRz584hKysL7dq1Q3h4uDniIyKyOlkmLAU/fk00trz2ZIVtcgs1yCkowrubYqB+ZO6NOT2/LAoqGzliP+gryvUM8c6G4iQm9oM+UNmI83Mwxpvrz+FCwsNE8X62fk9QrwX7kZRh+uISD7ILUMvIOVKH/76PzLzqs6TB3thk7LiQiI+ebYW41Fz4u9lVeQ4mEZGpVHkiQ+fOndG5c2dTxkJERP8SE1/+XKKSoWM5BRp0/mQvUv/5YF/f3V6U2PIttHR7XoHWIhOxDafKHjonCAJkMplZkjCgeI7a/GFtzHJuazF6VfEcvRdD6+HpLw9hyf+1Q//WtSWOiohqOoMSsS+++MLgE77++utVDoaIiKom9ZHelZv3H68KHYnDXqlAjhnKuP/bsRvGL45cXY35p2hKbGIGEzEikpxBidiCBQv0nqekpCAnJweurq4AgLS0NNjb28PLy4uJGBERkQEUIg2Nq22G+Vx3HuSa/JxiSM4s7nXMyjd/AkxEVBmDinXcuHFD9/jwww/Rpk0bXLp0CampqUhNTcWlS5fQrl07zJkzx9zxEhGRGZRXcY5qJm0lFShTs01T6VAqKw9bbrVKIqo5jK6a+N577+HLL79EQECAbltAQAAWLFiA6dOnmzQ4IiJrk1NgnQUOvjlwHQeupEgdhuQy8wqlDsEiiFX0hYioJjM6Ebt79y6Kikp/0NBoNEhKSjJJUEREj0rOzMMvJ+KkDsMgZqrMLooRK48jMb1qi0hXFx0/2i11CCZXleUCtNb8i2ygrPwiXPtnEWgiIikYnYj17NkT//nPf3Dq1CndtujoaIwfP54l7InILKZtjMHbG84hr9Dy53UUmqGSYHkLFZujamFShnGJ2K6L1esLuGwRimeUyDThMgcVKdIa/3vyIMe6hx4aouXMv9Bz3n6jf+eJiEzF6ERs5cqV8PHxQUhICFQqFVQqFTp06ABvb28sX77cHDESUQ33d3Km1CEYLK/I9B/kO328B/Wn/on4tIcFEi7dzUDY3D0mv9Y5IxdEnr/zisljIOkpbYz+eGC1cgs0OHAlBQ+yC5CdX4SUzLKXEUjJzMfsPy6gUGOZyzYQkfUxeh0xT09PbN26FVeuXMHly5cBAIGBgWjatKnJgyMiAqxrvsrNe6YvHV8yXHDMqhN4rWdjPN3aF6sO30CqGXot3tscg8Ht/GCvNOztobKiDmW5kFD+2mg1UaFGgNLGfBUUb93Lwa372ajn7mDwMWfi0kwaQ36RBgVFWjipbU16XlMZsfI46tSyQ2MvRxz++x6uftivVJvlh65j1eGb6NLUE90DvCSIkoiqmyp/5dW0aVMMHDgQAwcOZBJGRDWCIUMjh3971GzXj03KxMS1pwEAl+6ar5fwopkTpaFfR5n1/NYm18xDbjPzi9BrwQGjjtkXa9rCLc8vjUK/RQdRZIG9SSU//zsPcrEvNgWFGgE/Hb9dakiwnRV9IURE1sHoHrExY8ZUuH/lypVVDoaIyFIVarQIfG87PhjUEi91rCdpLDHx6Thv5BBCY7z+02kciexpUNvLiZm4kJCOFr4uBp9fUwMKQRhjX2wynmnjZ9ZrGDqf8HpKFv77Y7TJr1/y+1pggYnYtpjEUtvOxqVh8+l4tK1bC1P7BgIAZBBn3TciqjmM7hF78OCB3iM5ORl79uzBxo0bkZaWZoYQiYikV5I8/HYmXuJIiodRmZOxRST6f3EI8Wm52BebbKaIqrdJP5+ROgSdST+fwZUkwyoJZv/zeyIIAtYcu4X03MpL/y+wwDmFX+y+WmqbjUKGYzdSsWz/NQkiIqKawugesU2bNpXaptVqMX78eDRq1MgkQRERWaoTNx9g4tpTWPx/7SSLwdyL6WbmGV/Nb/Sq47iSlIWbH/c3Q0TVn6nnZFWVMT2tqdkFUNrIceJGKt7dFIOzcWn49PmgCo/59qD1LaT80/Hb+HjbZYx5okHxBnboEpGJmKQsklwuR0REBBYsWGCK0xERWbQt5+4iS6TS41JwUhn9HZ3BvShi+O2s9L2Wxvr5+G2zX+PbA9eRW6DBuTtpmLj2FL47cvOxzqe0kaPJu9vwf8uPAQB+OXlHVwp+zOoTeHfT+ccNWTLZ+Q/n7c34LUavt2/C2lNlHUJEZDTj323Lce3atTIXeiYiqg6up2TrPc8pKIJjFRKWmkijFdBo2lb0a+WDL4ebvydxxm8X0NLPBXa2CjSr7WzwcbGJ0i2T4OWkMvs1Ptx6CfN2xiKvsHie1pZzd/F069pwc1BCJjN+/tP7Wy6W2vbS8mPwclLh8LX7xdd8ttXjBS2RHRcezhsr1Oh3geWIuNYcEVVvRn+KiIiI0HsuCALu3r2LP//8EyNHjjRZYEREJUrmZxVotJKVsu/3xUG95z8di8Ok8Ca654IgVOnDrCXKzC/Cl7uvolcLHwT4OOm2F2m0sFFUPJAit0ADO6X+PSr4p1DE1vOJiL612/QBl+G5r44AgFFDJQcvPWKucCpVoBFnvFtJElYi+INdeLp17SoNtf3z3N1S264mZ+Fq8sPe0bxCjVUtP1GirIW9q7IwNhFRRYwemnj69Gm9x7lz5wAA8+bNw8KFC00dHxERSvIbQ8rHi2XBrodFB36IuomOH4mTYIhl3s4r6L2wuOR5XqEGX++/hsbvbqu04mGzGdtx5O97mPTzadxNzy21Pymj7MVyze37qJt4dsnhCttIOdxUyqIQW87dxb7YZHwfddPk575xL7vyRlbiyz1/6z3PL9Kgy6d7ceCKaUv9E1HNYXSP2N69e80RBxFRuZwlXgQ2+Z95L/92+34OCjQavPfbBQAote5QdfHfH6N160oVarRQyCvu4SiZM1Snlh3e6h2IB2ZYeNpQv52JxzNt/DDjn3uUnJkHDwcV5PLq0XtpKqNWnTDLebPyi3DngekXOZdaoUaLOVsu4nZqDr47UrzIMxGRsYxOxHr06IGNGzfC1dVVb3tGRgYGDRqEPXv2mCo2IiKLEPegdM8OAHT5TP+LqUVllMGuDh5d3Pe7IzfRs5m3Qcct2XsN/VrVRv8vDpklLhkqL2A36ecz2Hz6YfGODh8W91ze/Lg/7mflw93R/HOzarIhy6rn4t1N3t2m+7chZfuJiMoiE4z8ClculyMxMRFeXl5625OTk+Hn54fCwpr3BykjIwMuLi5IT0+Hs7PhE8OJyDDPLz2Ck7ce4Pi7PeHlpBb9+oeu3sNLK46Jfl1LIJcB1Xn95ZWjQtAjsDixrD/1T4mjIWvVv3VtvNK5AdrWrSV1KERkAQzNDQzuESuZCwYAFy9eRGLiw4pCGo0G27dvh5+fXxXDJSKyXIoaPIytOidhAHDgyj1dIladGNJbSKbz57m7+PPcXYQ2cMP8YW3g52ondUhEZAUMLtbRpk0btG3bFjKZDD169ECbNm10j+DgYHzwwQeYMWOGOWMFACxZsgT169eHWq1GaGgojh8/XmH79evXIzAwEGq1Gq1atcLWrVv19guCgBkzZqB27dqws7NDeHg4rl6tnsOLiKzdqsM3pQ7BqtXcdLJ8q4/cREpmPoLn7JQ6FJMydRLG3x3DHLuRimX7HhZeSc8pxN30XF3lUCKiRxmciN24cQPXrl2DIAg4fvw4bty4oXvEx8cjIyMDY8aMMWesWLduHSIiIjBz5kycOnUKQUFB6N27N5KTk8tsf+TIEQwfPhxjx47F6dOnMWjQIAwaNAgxMTG6Np9++im++OILLFu2DMeOHYODgwN69+6NvLyyJ+cTkfkcu34f/1sTXe7+pfuuSVIQI7eweqyRyB6SsrX/cBfuZ0tXUMQa8HfHcD8cvYX6U/9E/al/Iuj9Heg0dw8ifjkjdVhEZIGMniMmpdDQULRv3x6LFy8GAGi1Wvj7++O1117D1KlTS7UfNmwYsrOzsWXLFt22jh07ok2bNli2bBkEQYCvry+mTJmCN998EwCQnp4Ob29vrF69Gi+88IJBcXGOGJFpPPnpHsSl5pZa+6n/FwdxISEDAHD6vadwKTEDuQUag4tGVFVGXiGc1bbYdPoO3lh31qzXIiJxSDVsM9DHCZcTM/GfLg1Rx80ef5xJwJReTeHuqEJ2fhECfJygtlVAEARotEKla/YRkeUy6Ryx33//HX379oWtrS1+//33CtsOHDjQuEgNVFBQgOjoaERGRuq2yeVyhIeHIyqq7KpMUVFRpRag7t27NzZv3gyguJcvMTER4eHhuv0uLi4IDQ1FVFRUuYlYfn4+8vMfroWTkZFR1ZdlFlVZWLasYx7N0WUyGQRBgCAAcrmsVPuS5yXHlOwTBAH5RVqobOR65/r3dUrOq9EKevNxHj1fea+rrO8SBKF47any4i3rtf/7PGXFWdk5KlOVduX9u+Q5AL2fW0U/q/LOUd7PNa9QC7WtvNT1y/qZZeUXwVYhh0YrwM5Wgcz8IjgoFbh5Pwd1atlBIZfB5p97nF2gwa372fBxUUMhk8FJbYucgiLEpRZXJ5y3IxbD2vvD3UEFuRy6JAwA2howhEwuA9rXd8Ok8CY4G5cOjVaL4R3q4nJiJgJ9nPD1geu4mJCBQ3/fg4+zGl2aeiC0gTvOxKXhhQ7+OHj1Hn6IuoX4tFy08HXWuz4RWTepvn2+nJgJAPj6wHXdtmHfHDX4eIVcBm8nFWQyGTo39sDmM/H4cnhbyGUyRPxyBln5RXCxs0Vkv2Zo6esCJ7UN4tNy4WpvC4VMBk8nFTJyi5CYkQeljRxyGWAjl8PHRY37Wfm4m56H1nVcoLZVQKmQI7ugCHsuJ0OjFXA7NQdPt64NHxc75BZooLaVQ2WjgAABMsiQV6SBk8oGcam5uJedj9ouatgq5HB3UCK3UAOVjQIZuYWQy2WwVyqgFQTYyOU4E5eGVn4uOBOXhpB6tSCgOFHOzC+CUiGHrUIGmUwGhVyGrH+2yWSArUKuW2D+0fehAo0WNvLibdn5GkBW/H7gqLLR+xzz6OcSmQwo1AjQCgLy/1nw3E6pQJH2n3NBgPyR90iFTIbcQg2y8ougtlHAXqVAXqEG9kob3M/Oh8pGgespWahTyx45BUXwclLjanIm6rk7ICkjDw08HFCo0UJto0DRP+/dJV8OyABoheJt+UVa2MiLX/+/iyZl5RXBSW1T/HNUyFHwT9vMvCI4qBTIL9LCzrb4vwKK35NLPg/lF2mgVMj1Ph+VKNIKUMhkEFD8c8sv0sJWIUdOQREcVQ9Thkc/E5R1nkfblPj3Z8qSbYZ+viv5Z0kzYz/nWiqDesQerZQol5f/DY1MJoNGY54FVxMSEuDn54cjR46gU6dOuu1vv/029u/fj2PHSlc0UyqV+O677zB8+HDdtq+++gqzZ89GUlISjhw5gieeeAIJCQmoXbu2rs3QoUMhk8mwbt26MmOZNWsWZs+eXWq7JfSIvf7Tafx+NkHSGIiIiIiIxBZcrxY2jA+TOgyDe8QM6vfWarW6cvVarbbch7mSMEsTGRmJ9PR03SMuLk7qkHRefbKh1CEQEREREYnujfCmUodgFKMXdJaKh4cHFAoFkpKS9LYnJSXBx8enzGN8fHwqbF/y36SkJL0esaSkJLRp06bcWFQqFVQqy1wEtFUdl1Lza4isRcD0bcgv0pb6He6z8IBuWE9DDwdcv5cNADj13lNwsbM1S3n5pIw8DF56BLsiumLHxSS8/tNpk1+DiKhEUB0X+LraIbtAA28nFQYE+aKhpwNu389BWGOPSo//99QAIrJ8BiViX3zxhcEnfP3116scTEWUSiWCg4Oxe/duDBo0CEBx79zu3bsxceLEMo/p1KkTdu/ejcmTJ+u27dy5Uze0sUGDBvDx8cHu3bt1iVdGRgaOHTuG8ePHm+V1EFH5XupYDysO3Si13Ubx8IPFzoiuoqzr5e2sxqF3egAA1DacNE9EjycqsgcS0nLRys8VSiP+ptSpZW9QOyZgRNbHoERswYIFBp1MJpOZLREDgIiICIwcORIhISHo0KEDFi5ciOzsbIwePRoAMGLECPj5+WHu3LkAgEmTJqFr166YN28e+vfvj59//hknT57EN998o4t38uTJ+OCDD9CkSRM0aNAA7733Hnx9fXXJHhGJ5+0+AXi5Y71S29U2Ct2/pVhc2daE1cu40K7leaG9P34+YTlDzMm6dWnqidd7NIaT2hY/n7iN+1kFGNelIWq72KG2Cxd6JqKHDErEbtwo/Q21FIYNG4aUlBTMmDEDiYmJaNOmDbZv3w5v7+IS1rdv39YrJhIWFoa1a9di+vTpmDZtGpo0aYLNmzejZcuWujZvv/02srOzMW7cOKSlpaFz587Yvn071Gq16K+PqKZT2ShQ38Oh3P1HI3uKGM1Dzna2JjsXkzDLEtrADXOfa4U+LX0watUJqcOhauCl0LoIqe8GAJg5oIXE0RCRJXusdcQ4HrkY1xEjMq/nlx7ByVsPcPzdnvByEv9Lkj2XkzBm9UnRr0vm926/Zni1S3GRo/pT/5Q4GrJmL7T3x6TwJuz1IiLTVk38txUrVqBly5ZQq9VQq9Vo2bIlli9fXuVgiYgsmYsJe8SsTfT08FLbhgTXMfj4j55tZcpwTGZXRBcM7+CPoSH+UodCVi7A2wk3P+6Pjwe3ZhJGREYxOhGbMWMGJk2ahAEDBmD9+vVYv349BgwYgDfeeAMzZswwR4xERJJSPTJH7d/8XB9+8Dr93lNihCMqd0f9CrFnZ/bCZ0OCDDpWbSvH4GA/fPp8a3OEZpC2dV1xblYv3fOegV5Y8n/t0NjLCXOfaw0X+5qbZIthbOcGcFCW//+PtfpxbKju33VqMfkioqoxOhFbunQpvv32W8ydOxcDBw7EwIEDMXfuXHzzzTf46quvzBEjEZGkWviWPazg5sf9cXhqD7TxdwUA1HJQihiVeB790GlnW/mH6qA6LgCABUPbQGWjwIDWvmaLrTKrR3eAs9oWHRsWz9lZMao9+reuXclRNU99d3v4uZp+2G+/Vj648H4fk59Xap2beODg290BAI29HSWOhoisldHriBUWFiIkJKTU9uDgYBQVFZkkKCKiRyVm5AEA5BLNR61sHuzXLwfjTFyaOMGIaHiH4mF7nZt44Pi0nth/JaXSsttv9Q7A/7o1QkpWPjwdpV9vsWRY6aIX2uJ6SrbE0ZSvjb+rZL9DHo5K7H2zGwQBaDhtq0nP3cCj+iQpfVr4YPuFRN1zfzd7fDemA0Lq1ZIwKiKyZkb3iL388stYunRpqe3ffPMNXnzxRZMERUT0KEeVjd5/pRDxVFO958emPazg6O2sRu8WZS8sb61Ov/cU5j73cEihl7MaQwyYTzWhe2PIZDJ4Oal1CewjxWyxYXyYyWMty6hO9THlkXvm7axGp0buFR4zrV+gucMqV2cDFuw1hwndG2Hj+Ccgk8kgN8PSEG7VqJe4We3SPeNdm3rCQcK/S0Rk3ar012PFihXYsWMHOnbsCAA4duwYbt++jREjRiAiIkLXbv78+aaJkohIYuO6NMT8nVd0z025tpilcVLZmHSYpcpGgY3/C0NDDwe42pv/g/mTTTww6xnjy4aP69IIH229bIaIKpdbqDH7NQJ9nPBOn0D8cTYBG0/Ho21dV7zVu+rJ55GpPRD28R69bcteagd3RxWGLIuCNRdUDqlXCydvPQAAuDsocT+7QOKIiKg6MjoRi4mJQbt27QAA165dAwB4eHjAw8MDMTExunY1vaQ9EVVvzurq+y14kdb0q521qyve8K05z7SsvJGFEaPn6PsxHeDlrEb3QC+88mRDeDg93jW1goC1r4TitzMJWHeyeEHsXs19IJfL8NuEJ6y6NyywtpMuEfN3s9dLxCL7StdzSkTVi9GfJPbu3WuOOIiIrIKTygbR7z0Fm2rcI1aV3pmFw9rg97MJZojGeLVE6HUztXFdGuKzv2LNeg0v54fFOJqXU4DGGLYKOcIae6C5rzM2n4nHmldCdcMbg/4pYFP6GBkKNda1rPm3I0IQfSsVsYlZAICmPk4SR0RE1UX1/SRBRGQGPZt5VVqwwtzeCG9aeaPHYGPkXKEX2vtjUFs/rBzV3kwRVW9NvR0tZqjrnEGG9yZ6/5PYudorEftBX4TUd6v0mG2TulQ5NnPp3cK73H11atnB00mFPi1ZaZOITM/oHrG8vDx8+eWX2Lt3L5KTk6HVavX2nzp1ymTBERFZCrWtAnMGtUSv5uV/aBPL6z0bY8GuK5U3rKLx3RoZ3LaptyM+HizdOmHVwfr/ilPAxBAvd6yHbk098eSn5hn9Yolrbj3btg7+upBUavtPr3aEl7P0lT+JqPoyOhEbO3YsduzYgeeffx4dOnTgXDAiqjFe7liv0jbDO9TFT8dvmy2GJxq7QyaTYXC7Othw6o5ZrvFK54YGt63KkgL/6doQX++/bvRx1ZXCDNUK/+29p5sb3Nbfzd7k11/7SiiSM/OhNmAdOrEFljHUcFLPpvB00k/CMvIKAQCCYF1DK4nIchmdiG3ZsgVbt27FE088YY54iIis2us9G5stEVswLEi3OHJLP2dsMMMAhEaeDnAycyGSN8KbMhF7hIPSvMlJSz9njO3cwKhjJoc3wcJdV00WQ5hE5fkN1bWpJ155sgEEAbh1P7tUEgYULzGw4tANNPKsPmujEZG0jH639fPzg5MTJ6oSkXgy86xnsXiFGUYJrB7dHvZKG7SvX0s3CuHljvVQz90eY1afNOm1Pn2+tVHrSbUVsRoikTloBAHfjenwyBbPMtt1D/TClQ/6Sj5HlIiqD6P/msybNw/vvPMObt26ZY54iIhKmT2wBeq521tMQYOK2JthcdduAV7o0MBNbyi4jUKO7gFeJr+Wysa43hkpF0G2drYKcYb2y2D8dTRmWMLA0gwL8Yez2gb1jBiKySSMiEzJ6E8MISEhyMvLQ8OGDWFvbw9bW1u9/ampqSYLjogIAMKbeyPcAopk1ATNaxtX1txJbVt5Iysy97lWiNx4XpRrqW0UKNSYv7dXVYXkwfuRUvfV1SfPt8Ynz7PQDBFJx+hEbPjw4YiPj8dHH30Eb29vFusgInqEnQUWIzBEoI8Ttr7+pFHDEquj4R3qipaIWbL03EKpQyAiqvaMTsSOHDmCqKgoBAUFmSMeIiKrJkYFPHP46LlWNT4Jo4eqUg3TmjQzsueXiMgcjB6vEBgYiNzcXHPEQkREEnE2c6VEkk6aGXq3WtdxMfk5xfRUM9PPryQiMpbRidjHH3+MKVOmYN++fbh//z4yMjL0HkRERFS5zHxxqoHasKdTZ/bAFgBYdIOILIPRX4H26dMHANCzZ0+97YIgQCaTQaPRmCYyIiKq0KNzdD8fEoQ3158FAAwM8sXvZxOkCktyMgv9jG2rkKFQU7oaobnnWk/r18ys57cGgT5OuJyYiaEh/riekoXhHepKHRIRkfGJ2N69e8vdd/48JzgTEZnSpwZUdXNU2eD54DoI9HGCykaOlYdvmj2ul0Lrws1BafbrGKOFrzM8HFVwMsMSAqawcfwTyCkowrBvjpa5f8n/tcOEtaZfpbtL07LXxaqIu4Xd28e19fUncT+7AHZKBWY/01LqcIiIAFQhEevatave88zMTPz0009Yvnw5oqOjMXHiRJMFR0RkjZxUNiYbdjY0xL/SNl0Dij9ot/QTb97OB8+2qvKx5uoA+n5MB7g7qsxzchNo9a95VW/3CcCKgzd0z/u3ro3+rfuj/tQ/xQ6tlIFtfGFrI8Mb686WuT/LihZZBwC5XAZPJ8v93SCimqnKAzgOHDiAkSNHonbt2vj888/Ro0cPHD1a9rd8RERkvP90bVhpmy2vdcZHj5EUScHYRaMNZalJmMe/4lr8f23x6pMN8L9ujXFsWs9yjpKW2laBZ9vWKbX9v10bAQCKLHDB55Z+rIRIRNbFqB6xxMRErF69GitWrEBGRgaGDh2K/Px8bN68Gc2bNzdXjEREVsVUvWG9mvtU2qasXrAAb0eTXN+a/K9bI6lDKNfP40KRnvvwd+Lp1r54urUvAMBGYaET2v7RqaE7oq7f1z1X28oR6OOE13o0Mdk1Zg1ojll/XHzs8/RtWRsx8aWLhi16oc1jn5uIyBwMfgcYMGAAAgICcO7cOSxcuBAJCQn48ssvzRkbERFVwbD2ll+IQGXiqnVv9wk06flMqbGXE4Lr1ZI6jCp5Oqh2qW3bJ3dB/9altxtq2UvtsGJkiO75qCcaVPlcAODtXNzjWLKG36M9xIPb1cEzbfwe6/xEROZicI/Ytm3b8Prrr2P8+PFo0sR034QREVHZcguqVoXWVmH55crPzeqFgOnbpQ6DJNCnZdWTuLLYK20A5EPzz3BJB9XDoa8PcgpMei0iIlMy+CvJQ4cOITMzE8HBwQgNDcXixYtx7949c8ZGRERVYKOQY+vrT0odRoXMNU+MTCu/UCvKdUaF1dcrKf9C+8qL1PxbRl7xwtVa4eH8tcHtSs9zIyKyFAYnYh07dsS3336Lu3fv4j//+Q9+/vln+Pr6QqvVYufOncjMzDRnnERENcr/ujVChwZuVT6+ua9xhQvkZl7LqjpqVtsZ52b1kjoMs3K1txXlOrMGtsDc5x4OKfx4cOXLNvxbHVc7AICfq71u2+MMoSQiMjejB+k7ODhgzJgxOHToEM6fP48pU6bg448/hpeXFwYOHGiOGImIapy3+wRCaeJ5VBVxsNC1twzRubGHSc+37KV2mNC98uIfCjngrBYnUZGKpRcTedSz7erg2xEhaFfXVepQiIgM8lh/YQMCAvDpp5/izp07+Omnn0wVExERkcHqudtX3sgIfVrWxvhujU16TmvX1gzJzcpRIfjm5eBS24PqGLceXlJGHgBAqZDjqebekLF3l4ishEm+AlUoFBg0aBAGDRpkitMREZHI1Lacs2Ws+Ae5Uodgdpn/zLtSmqFnrEegd6lta14JNTqxtrNVIKdAYxVFaoiIHmU9Yw6IiKyEoxUO8+OHWOP51bKrcH8bf1fYyKvHz/Xfi1KbyxONPVCnlnGJWEkHWElPWDX5kRNRDcBEjIiIrJqva8UJkbm4O1ScnCwfGYKdEV1FisbM/kluSkrEW5JRYfWhtn34cUYmk8HFrnrP3SOi6sH6vrYlIiKTs+aqiUNDjC91bgq1XdQV7vdwVInWkySW9NxCqUMoZUL3xnjlyYZ625a+1A7Hb6RKFBERkWHYI0ZERFY9R0zM6pL13O3xTBtfAEC7erVEu67UnNXF39vailhFcfXo9lg3riMAwEld/vfGMpms1O9vWCMPTA5vatb4iIgeF3vEiIhquDFP1Jfkuh892wr7ryTjrwtJkly/KnZHdIVCLsMng1vrPvx3aOCm1/virLZBRl6RVCGalZj9pt0CvAAAuyK6QiYDXlp+DE5qG1xJygIAfPp8a9xIyRIxIiIi02IiRkRUTdV3t8fN+zkVthnUxhczBrQQKSJ9/xdaF50auVtVIlayrtajPTCu/8xHaujpgOsp2fjqxWDceVDxz91aBHg7AQD6t/LFzXs5eKFDXdFjaOzlCADYPOEJKOQyhHywC4B0Q1KJiEyFiRgRUTU1IMgXX+75u8I21jw3zNIsGNoG97Pz0bmJaReYfhyD/hlGWVUh9d1wblYvOKttJX9d3s4Vz8kjIrI2TMSIiKopZ3XlleO6BniKEEn11sjLEbiYhHru9gjyd5U6HJ0uTT3x6fNBj30eQ36PxDRnUEsIguVVbyQiMhYTMSIiE8sr1EgdAgDghQ7+kMmAD/68VG6bhh6OIkZUPU3o3hgd6rvB1V5pkvO1r18LJ24+eOzzNPNxErWQiVhe7lhP6hCIiEyi+v2FJiKSWJGFrLXkpLYtVda7unGzV8JeafqKj3a2CjzV3Nugto4qG3QP9DLZtb96MRh/vt75sc8zvlsjE0RDRETmYjWJWGpqKl588UU4OzvD1dUVY8eORVZWxdWS8vLyMGHCBLi7u8PR0RGDBw9GUtLDSeFnz57F8OHD4e/vDzs7OzRr1gyLFi0y90shIiIT2T2lq1lKqivkMnw7IgS9DEzGTMnTSYUWvi6PfR5T9dAREZF5WE0i9uKLL+LChQvYuXMntmzZggMHDmDcuHEVHvPGG2/gjz/+wPr167F//34kJCTgueee0+2Pjo6Gl5cXfvzxR1y4cAHvvvsuIiMjsXjxYnO/HCKqxqT48E5ERETWxSrmiF26dAnbt2/HiRMnEBISAgD48ssv0a9fP3z++efw9S1dFSo9PR0rVqzA2rVr0aNHDwDAqlWr0KxZMxw9ehQdO3bEmDFj9I5p2LAhoqKisHHjRkycOLHcePLz85Gfn697npGRYYqXSUTVxGdDgrBj9g6pw6Aays5Wgefa+UkdBhERVcIqesSioqLg6uqqS8IAIDw8HHK5HMeOHSvzmOjoaBQWFiI8PFy3LTAwEHXr1kVUVFS510pPT4ebm1uF8cydOxcuLi66h78/1zIhoodc7Gyx6IU2UodBNdTRaT3x/jMtpQ6DiIgqYRWJWGJiIry89CdC29jYwM3NDYmJieUeo1Qq4erqqrfd29u73GOOHDmCdevWVTrkMTIyEunp6bpHXFyc4S+GiGqEum72VT526YvtTBhJ+ZzUNvB15dpM1Y2LnS0Ucq4PR0Rk6SQdmjh16lR88sknFba5dKn8ssumFBMTg2eeeQYzZ85Er169KmyrUqmgUqlEiYuIahZ7pQJ9W9U2+3WaeDlixxtdIOOCzhVyUBW/Tb7UsS6UZigKQkRENZekidiUKVMwatSoCts0bNgQPj4+SE5O1tteVFSE1NRU+Pj4lHmcj48PCgoKkJaWptcrlpSUVOqYixcvomfPnhg3bhymT59epddCRGRtmIRVbnJ4EzipbTBrQAvI2ctEREQmJGki5unpCU9Pz0rbderUCWlpaYiOjkZwcDAAYM+ePdBqtQgNDS3zmODgYNja2mL37t0YPHgwACA2Nha3b99Gp06ddO0uXLiAHj16YOTIkfjwww9N8KqIiKquFkuOW5R67g6cb0VERGZhFeMsmjVrhj59+uDVV1/F8ePHcfjwYUycOBEvvPCCrmJifHw8AgMDcfz4cQCAi4sLxo4di4iICOzduxfR0dEYPXo0OnXqhI4dOwIoHo7YvXt39OrVCxEREUhMTERiYiJSUlIke61EVD1oqrio85jODUwcCVmrln7OBrf1dCoeLt+3ZdmjRIiIyPJYRSIGAGvWrEFgYCB69uyJfv36oXPnzvjmm290+wsLCxEbG4ucnBzdtgULFuDpp5/G4MGD0aVLF/j4+GDjxo26/b/++itSUlLw448/onbt2rpH+/btRX1tRFT9uNrbVum4WlU8jqqfCd0ao567YUVf5DIgKrIH5g0NMnNURERkKlaxjhgAuLm5Ye3ateXur1+/PgRB/xtotVqNJUuWYMmSJWUeM2vWLMyaNcuUYRIR/cOy5xNZSlW9/CKN1CFYrL6taqNvq9qoP/XPStvKIENtFzsRoiIiIlOxmkSMiIgen71SgQBvJ0zo3ljqUAAARZqqDeGkh+rUssP/ulnG/SQiIsMxESMiMgvLSzAGt/PDU8190MeC5hEF+jjhlc4NsPzQDalDsVoH3+7OCphERFbIauaIERFZk8y8IqlDKGXe0DYWlYQBgI1CjulPN5c6DKsV6OPEJIyIyEqxR4yIiKyWnVIhdQiSWTW6PRq4O0gdBhERVRETMSIislpKRc0d2NE9wEvqEIiI6DHU3HcwIqIaomSNqerm2bZ+kFtI9UdzUtk8fKv2dq6e95KIqCZijxgRUTW39MV2OH4zVeowTM5RVTPewjaMD0N+kRZ2tgrYKRVYc+wW2vi7Sh0WERE9pprxLkZEZCUaeTqa/Jwh9d0QUt/N5OcVy9znWmH+zitIycyXOhRJtPRz0Xs+vT+LmxARVQccmkhEZCHOzuyFIPZ0lDK8Q124OyilDoOIiMikmIgREVkIFztbqUMgIiIikTARIyIiIiIiEhkTMSIiIiIiIpExESMiIqsR1sgdHRtab+ERIiKiEkzEiIjI4nUPLF68+MexoXi3H6sGEhGR9WP5eiIiskh+rnao9U+1xIinmuL/OtSFXC6DnVIBAKjnbi9leERERI+FiRgREVmk5SND0MDDAQBgq5DD36048Wrs5YjVo9ujY0N3KcMjIiJ6LByaSERkBvXcHVCnlp3UYVg1W4UcaltFmfu6BXiVu4+IiMgaMBEjIjIDNwclDr3TQ+owiIiIyEIxESMiIiIiIhIZEzEiIiIiIiKRMREjIiIiIiISGRMxIiIiIiIikTERIyIiIiIiEhnXESMiklj7+rUQ3sxb6jCIiIhIREzEiIgkNqlnU3Ru4iF1GERERCQiDk0kIiIiIiISGRMxIiIiIiIikTERIyIiIiIiEhkTMSIiIiIiIpExESMiIskF16sldQhERESiYiJGRESSWzmyPbZPflLqMIiIiETD8vVERCQ5F3tbuNjb6m3LL9JIFA0REZH5sUeMiIgsUkGRVuoQiIiIzIaJGBERERERkciYiBEREREREYmMiRgREREREZHImIgREZlRxFNNobThn1oiIiLSx08HRERm9HrPJnjv6eZSh2GV7JQKqUMgIiIyGyZiRERkcZa9FIwAbyepwyAiIjIbriNGREQWRW0rR5+WPlKHQUREZFZW0yOWmpqKF198Ec7OznB1dcXYsWORlZVV4TF5eXmYMGEC3N3d4ejoiMGDByMpKanMtvfv30edOnUgk8mQlpZmhldARERERERUzGoSsRdffBEXLlzAzp07sWXLFhw4cADjxo2r8Jg33ngDf/zxB9avX4/9+/cjISEBzz33XJltx44di9atW5sjdCIiIiIiIj1WkYhdunQJ27dvx/LlyxEaGorOnTvjyy+/xM8//4yEhIQyj0lPT8eKFSswf/589OjRA8HBwVi1ahWOHDmCo0eP6rVdunQp0tLS8Oabb4rxcoiohprzTAtM7N4YANDI0wFNvBwBAB5OSinDsjjuDiqpQyAiIjI7q5gjFhUVBVdXV4SEhOi2hYeHQy6X49ixY3j22WdLHRMdHY3CwkKEh4frtgUGBqJu3bqIiopCx44dAQAXL17E+++/j2PHjuH69esGxZOfn4/8/Hzd84yMjKq+NCKqATo39kBjT0d0C/DCptPxAIDpTzdH9wAvpOcWwsXOVuIILcd/ujZEz0BvqcMgIiIyO6voEUtMTISXl5feNhsbG7i5uSExMbHcY5RKJVxdXfW2e3t7647Jz8/H8OHD8dlnn6Fu3boGxzN37ly4uLjoHv7+/sa9ICKqURp4OGDXlK7wd7MvtY9JmL7Ivs3QoYGb1GEQERGZnaSJ2NSpUyGTySp8XL582WzXj4yMRLNmzfDSSy8ZfVx6erruERcXZ6YIiYiIiIioOpJ0aOKUKVMwatSoCts0bNgQPj4+SE5O1tteVFSE1NRU+PiUXeLYx8cHBQUFSEtL0+sVS0pK0h2zZ88enD9/Hr/++isAQBAEAICHhwfeffddzJ49u8xzq1QqqFScw0BExvNyKv7b4aiyipHhREREZCaSfhLw9PSEp6dnpe06deqEtLQ0REdHIzg4GEBxEqXVahEaGlrmMcHBwbC1tcXu3bsxePBgAEBsbCxu376NTp06AQA2bNiA3Nxc3TEnTpzAmDFjcPDgQTRq1OhxXx4RUSnPtvODi50tQurVkjoUIiIikpBMKOkGsnB9+/ZFUlISli1bhsLCQowePRohISFYu3YtACA+Ph49e/bE999/jw4dOgAAxo8fj61bt2L16tVwdnbGa6+9BgA4cuRImdfYt28funfvjgcPHpSaW1aRjIwMuLi4ID09Hc7Ozo/3QomIiIiIyGoZmhtYzdiYNWvWYOLEiejZsyfkcjkGDx6ML774Qre/sLAQsbGxyMnJ0W1bsGCBrm1+fj569+6Nr776SorwiYiIiIiIdKymR8ySsUeMiIiIiIgAw3MDqyhfT0REREREVJ0wESMiIiIiIhIZEzEiIiIiIiKRMREjIiIiIiISGRMxIiIiIiIikVlN+XpLVlJ4MiMjQ+JIiIiIiIhISiU5QWXF6ZmImUBmZiYAwN/fX+JIiIiIiIjIEmRmZsLFxaXc/VxHzAS0Wi0SEhLg5OQEmUwmaSwZGRnw9/dHXFwc1zSzYLxP1oP3ynrwXlkH3ifrwXtlPXivLIsgCMjMzISvry/k8vJngrFHzATkcjnq1KkjdRh6nJ2d+T+iFeB9sh68V9aD98o68D5ZD94r68F7ZTkq6gkrwWIdREREREREImMiRkREREREJDImYtWMSqXCzJkzoVKppA6FKsD7ZD14r6wH75V14H2yHrxX1oP3yjqxWAcREREREZHI2CNGREREREQkMiZiREREREREImMiRkREREREJDImYkRERERERCJjIlaNLFmyBPXr14darUZoaCiOHz8udUg1mjH3Y/Xq1ZDJZHoPtVotYrT0bwcOHMCAAQPg6+sLmUyGzZs3Sx1SjWbs/di3b1+p/6dkMhkSExPFCZhKmTt3Ltq3bw8nJyd4eXlh0KBBiI2NlTqsGqsq94PvVZZl6dKlaN26tW4R506dOmHbtm1Sh0VGYCJWTaxbtw4RERGYOXMmTp06haCgIPTu3RvJyclSh1YjVeV+ODs74+7du7rHrVu3RIyY/i07OxtBQUFYsmSJ1KEQqn4/YmNj9f6/8vLyMlOEVJn9+/djwoQJOHr0KHbu3InCwkL06tUL2dnZUodWI1X1fvC9ynLUqVMHH3/8MaKjo3Hy5En06NEDzzzzDC5cuCB1aGQglq+vJkJDQ9G+fXssXrwYAKDVauHv74/XXnsNU6dOlTi6msfY+7F69WpMnjwZaWlpIkdKhpDJZNi0aRMGDRokdSgEw+7Hvn370L17dzx48ACurq6ixUaGS0lJgZeXF/bv348uXbpIHU6NZ8j94HuV5XNzc8Nnn32GsWPHSh0KGYA9YtVAQUEBoqOjER4ertsml8sRHh6OqKgoCSOrmap6P7KyslCvXj34+/vzGy0iE2nTpg1q166Np556CocPH5Y6HHpEeno6gOIPjiQ9Q+8H36ssk0ajwc8//4zs7Gx06tRJ6nDIQEzEqoF79+5Bo9HA29tbb7u3tzfnQ0igKvcjICAAK1euxG+//YYff/wRWq0WYWFhuHPnjhghE1U7tWvXxrJly7BhwwZs2LAB/v7+6NatG06dOiV1aITiUQKTJ0/GE088gZYtW0odTo1n6P3ge5XlOX/+PBwdHaFSqfDf//4XmzZtQvPmzaUOiwxkI3UARAR06tRJ7xussLAwNGvWDF9//TXmzJkjYWRE1ikgIAABAQG652FhYbh27RoWLFiAH374QcLICAAmTJiAmJgYHDp0SOpQCIbfD75XWZ6AgACcOXMG6enp+PXXXzFy5Ejs37+fyZiVYI9YNeDh4QGFQoGkpCS97UlJSfDx8ZEoqprLFPfD1tYWbdu2xd9//22OEIlqpA4dOvD/KQswceJEbNmyBXv37kWdOnWkDqfGe5z7wfcq6SmVSjRu3BjBwcGYO3cugoKCsGjRIqnDIgMxEasGlEolgoODsXv3bt02rVaL3bt3c5ywBExxPzQaDc6fP4/atWubK0yiGufMmTP8f0pCgiBg4sSJ2LRpE/bs2YMGDRpIHVKNZor7wfcqy6PVapGfny91GGQgDk2sJiIiIjBy5EiEhISgQ4cOWLhwIbKzszF69GipQ6uRKrsfI0aMgJ+fH+bOnQsAeP/999GxY0c0btwYaWlp+Oyzz3Dr1i288sorUr6MGi0rK0vvW94bN27gzJkzcHNzQ926dSWMrGaq7H5ERkYiPj4e33//PQBg4cKFaNCgAVq0aIG8vDwsX74ce/bswY4dO6R6CTXehAkTsHbtWvz2229wcnLSzZl1cXGBnZ2dxNHVPIbcD75XWbbIyEj07dsXdevWRWZmJtauXYt9+/bhr7/+kjo0MpRA1caXX34p1K1bV1AqlUKHDh2Eo0ePSh1SjVbR/ejataswcuRI3fPJkyfr2np7ewv9+vUTTp06JUHUVGLv3r0CgFKPR+8biaey+zFy5Eiha9euuvaffPKJ0KhRI0GtVgtubm5Ct27dhD179kgTPAmCIJR5/wAIq1atkjq0GsmQ+8H3Kss2ZswYoV69eoJSqRQ8PT2Fnj17Cjt27JA6LDIC1xEjIiIiIiISGeeIERERERERiYyJGBERERERkciYiBEREREREYmMiRgREREREZHImIgRERERERGJjIkYERERERGRyJiIERERERERiYyJGBERERERkciYiBERERlo1KhRGDRokNRhEBFRNWAjdQBERESWQCaTVbh/5syZWLRoEQRBECkiIiKqzpiIERERAbh7967u3+vWrcOMGTMQGxur2+bo6AhHR0cpQiMiomqIQxOJiIgA+Pj46B4uLi6QyWR62xwdHUsNTezWrRtee+01TJ48GbVq1YK3tze+/fZbZGdnY/To0XByckLjxo2xbds2vWvFxMSgb9++cHR0hLe3N15++WXcu3dP5FdMRERSYiJGRET0GL777jt4eHjg+PHjeO211zB+/HgMGTIEYWFhOHXqFHr16oWXX34ZOTk5AIC0tDT06NEDbdu2xcmTJ7F9+3YkJSVh6NChEr8SIiISExMxIiKixxAUFITp06ejSZMmiIyMhFqthoeHB1599VU0adIEM2bMwP3793Hu3DkAwOLFi9G2bVt89NFHCAwMRNu2bbFy5Urs3bsXV65ckfjVEBGRWDhHjIiI6DG0bt1a92+FQgF3d3e0atVKt83b2xsAkJycDAA4e/Ys9u7dW+Z8s2vXrqFp06ZmjpiIiCwBEzEiIqLHYGtrq/dcJpPpbSupxqjVagEAWVlZGDBgAD755JNS56pdu7YZIyUiIkvCRIyIiEhE7dq1w4YNG1C/fn3Y2PBtmIiopuIcMSIiIhFNmDABqampGD58OE6cOIFr167hr7/+wujRo6HRaKQOj4iIRMJEjIiISES+vr44fPgwNBoNevXqhVatWmHy5MlwdXWFXM63ZSKimkImCIIgdRBEREREREQ1Cb96IyIiIiIiEhkTMSIiIiIiIpExESMiIiIiIhIZEzEiIiIiIiKRMREjIiIiIiISGRMxIiIiIiIikTERIyIiIiIiEhkTMSIiIiIiIpExESMiIiIiIhIZEzEiIiIiIiKRMREjIiIiIiIS2f8DTqrkrMYieNYAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "file_path=\"/content/ravdess/Actor_01/03-01-01-01-01-01-01.wav\"\n",
        "y,sr=librosa.load(file_path)\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "librosa.display.waveshow(y, sr=sr)\n",
        "plt.title('Waveform')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMYoYRfEUNuo"
      },
      "source": [
        "**count audion files per Actor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cFKdC57T293",
        "outputId": "041dd7b5-cb09-437a-e665-611f2377d553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actor Actor_01 has 60 wav files\n",
            "Actor Actor_02 has 60 wav files\n",
            "Actor Actor_03 has 60 wav files\n",
            "Actor Actor_04 has 60 wav files\n",
            "Actor Actor_05 has 60 wav files\n",
            "Actor Actor_06 has 60 wav files\n",
            "Actor Actor_07 has 60 wav files\n",
            "Actor Actor_08 has 60 wav files\n",
            "Actor Actor_09 has 60 wav files\n",
            "Actor Actor_10 has 60 wav files\n",
            "Actor Actor_11 has 60 wav files\n",
            "Actor Actor_12 has 60 wav files\n",
            "Actor Actor_13 has 60 wav files\n",
            "Actor Actor_14 has 60 wav files\n",
            "Actor Actor_15 has 60 wav files\n",
            "Actor Actor_16 has 60 wav files\n",
            "Actor Actor_17 has 60 wav files\n",
            "Actor Actor_18 has 60 wav files\n",
            "Actor Actor_19 has 60 wav files\n",
            "Actor Actor_20 has 60 wav files\n",
            "Actor Actor_21 has 60 wav files\n",
            "Actor Actor_22 has 60 wav files\n",
            "Actor Actor_23 has 60 wav files\n",
            "Actor Actor_24 has 60 wav files\n"
          ]
        }
      ],
      "source": [
        "for actor in sorted(actor_dir):\n",
        "  actor_path=os.path.join(data_dir,actor)\n",
        "  wav_files=[f for f in os.listdir(actor_path) if f.endswith(\".wav\")]\n",
        "  print(\"Actor\",actor,\"has\",len(wav_files),\"wav files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0p0UDGiX45Q"
      },
      "source": [
        "#Extract Feature like MFCC, Chroma, Mel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "takfHS1HJGee"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path):\n",
        "  X, sample_rate=librosa.load(file_path,res_type='kaiser_fast')\n",
        "\n",
        "  #Extract Features\n",
        "  mfccs=np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=40).T,axis=0)\n",
        "  chroma=np.mean(librosa.feature.chroma_stft(y=X,sr=sample_rate).T,axis=0)\n",
        "  mel=np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0)\n",
        "\n",
        "  return np.hstack([mfccs,chroma,mel])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "YpAv7EARYEIb"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "emotion = {\n",
        "    1: 'neutral',\n",
        "    2: 'calm',\n",
        "    3: 'happy',\n",
        "    4: 'sad',\n",
        "    5: 'angry',\n",
        "    6: 'fearful',\n",
        "    7: 'disgust',\n",
        "    8: 'surprised'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "CvK0GxkWZt07"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "base_dir = '/content/ravdess'\n",
        "\n",
        "for root, _, files in os.walk(base_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            parts = file.split('-')\n",
        "            try:\n",
        "                emotion_code = int(parts[2])\n",
        "                emotion_label = emotion.get(emotion_code)\n",
        "                if emotion_label is None:\n",
        "                    continue  # skip unknown emotion codes\n",
        "            except:\n",
        "                continue  # skip malformed filenames\n",
        "\n",
        "            file_path = os.path.join(root, file)\n",
        "            features = extract_features(file_path)\n",
        "            if features is not None:\n",
        "                data.append(features)\n",
        "                labels.append(emotion_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "bxCAZS8XncME"
      },
      "outputs": [],
      "source": [
        "for root, _, files in os.walk('/content/ravdess'):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            parts = file.split('-')\n",
        "            emotion_code = int(parts[2])\n",
        "            emotion_label = emotion.get(emotion_code, 'unknown')\n",
        "\n",
        "            filepath = os.path.join(root, file)\n",
        "\n",
        "            features = extract_features(file_path)\n",
        "            data.append(features)\n",
        "            labels.append(emotion_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gsp6BBl8neRl",
        "outputId": "bae35c91-1e3e-4f13-c814-a3d65e4ea8ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'!'\t\t        kaggle.json   ravdess-emotional-speech-audio.zip\n",
            " emotion_features.csv   ravdess       sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXPFBd9dirz_",
        "outputId": "ad3c2be6-e659-44e8-96d8-f7b03a63e848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved all features with emotion labels to 'all_emotion_features.csv'\n"
          ]
        }
      ],
      "source": [
        "df=pd.DataFrame(data)\n",
        "df['labels']=labels\n",
        "df.to_csv('emotion_features.csv',index=False)\n",
        "print(\"Saved all features with emotion labels to 'all_emotion_features.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "siAviSF9m0Cl",
        "outputId": "6b5402e4-1591-4b7f-a2cf-1f06f497a374"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-12e89eee-fdf6-4887-a37b-2640282541a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-628.423950</td>\n",
              "      <td>71.823265</td>\n",
              "      <td>3.100013</td>\n",
              "      <td>19.572556</td>\n",
              "      <td>9.635880</td>\n",
              "      <td>9.022594</td>\n",
              "      <td>9.414989</td>\n",
              "      <td>-3.085639</td>\n",
              "      <td>-9.131564</td>\n",
              "      <td>8.447961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>4.240441e-07</td>\n",
              "      <td>2.019719e-08</td>\n",
              "      <td>1.063755e-09</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-435.661377</td>\n",
              "      <td>35.057297</td>\n",
              "      <td>-8.425894</td>\n",
              "      <td>11.188873</td>\n",
              "      <td>-0.842001</td>\n",
              "      <td>6.655818</td>\n",
              "      <td>-1.734082</td>\n",
              "      <td>1.331836</td>\n",
              "      <td>-8.471194</td>\n",
              "      <td>6.216380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016836</td>\n",
              "      <td>0.011611</td>\n",
              "      <td>0.007806</td>\n",
              "      <td>0.005089</td>\n",
              "      <td>0.001576</td>\n",
              "      <td>0.000433</td>\n",
              "      <td>5.963890e-05</td>\n",
              "      <td>5.424370e-06</td>\n",
              "      <td>2.068020e-07</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-556.891602</td>\n",
              "      <td>44.362152</td>\n",
              "      <td>1.242800</td>\n",
              "      <td>16.261635</td>\n",
              "      <td>-2.510679</td>\n",
              "      <td>13.024461</td>\n",
              "      <td>-2.505990</td>\n",
              "      <td>-2.787434</td>\n",
              "      <td>-9.724454</td>\n",
              "      <td>5.876904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000334</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000080</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>2.594656e-06</td>\n",
              "      <td>3.096257e-07</td>\n",
              "      <td>1.102683e-08</td>\n",
              "      <td>surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-644.404663</td>\n",
              "      <td>58.288540</td>\n",
              "      <td>3.313139</td>\n",
              "      <td>19.299717</td>\n",
              "      <td>11.171613</td>\n",
              "      <td>10.345291</td>\n",
              "      <td>3.411453</td>\n",
              "      <td>4.594384</td>\n",
              "      <td>-1.304071</td>\n",
              "      <td>7.556545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.036664e-07</td>\n",
              "      <td>3.115553e-08</td>\n",
              "      <td>9.106774e-10</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-638.208130</td>\n",
              "      <td>68.423119</td>\n",
              "      <td>10.780132</td>\n",
              "      <td>28.830057</td>\n",
              "      <td>11.801587</td>\n",
              "      <td>13.568628</td>\n",
              "      <td>1.361726</td>\n",
              "      <td>-0.862681</td>\n",
              "      <td>-5.211549</td>\n",
              "      <td>10.154545</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.104687e-07</td>\n",
              "      <td>4.767324e-08</td>\n",
              "      <td>2.764471e-09</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 181 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12e89eee-fdf6-4887-a37b-2640282541a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12e89eee-fdf6-4887-a37b-2640282541a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12e89eee-fdf6-4887-a37b-2640282541a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a8793310-f5b8-4515-9a07-74eac6608efe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8793310-f5b8-4515-9a07-74eac6608efe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a8793310-f5b8-4515-9a07-74eac6608efe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            0          1          2          3          4          5  \\\n",
              "0 -628.423950  71.823265   3.100013  19.572556   9.635880   9.022594   \n",
              "1 -435.661377  35.057297  -8.425894  11.188873  -0.842001   6.655818   \n",
              "2 -556.891602  44.362152   1.242800  16.261635  -2.510679  13.024461   \n",
              "3 -644.404663  58.288540   3.313139  19.299717  11.171613  10.345291   \n",
              "4 -638.208130  68.423119  10.780132  28.830057  11.801587  13.568628   \n",
              "\n",
              "          6         7         8          9  ...       171       172       173  \\\n",
              "0  9.414989 -3.085639 -9.131564   8.447961  ...  0.000016  0.000014  0.000012   \n",
              "1 -1.734082  1.331836 -8.471194   6.216380  ...  0.016836  0.011611  0.007806   \n",
              "2 -2.505990 -2.787434 -9.724454   5.876904  ...  0.000334  0.000318  0.000186   \n",
              "3  3.411453  4.594384 -1.304071   7.556545  ...  0.000021  0.000018  0.000014   \n",
              "4  1.361726 -0.862681 -5.211549  10.154545  ...  0.000028  0.000025  0.000025   \n",
              "\n",
              "        174       175       176           177           178           179  \\\n",
              "0  0.000014  0.000013  0.000004  4.240441e-07  2.019719e-08  1.063755e-09   \n",
              "1  0.005089  0.001576  0.000433  5.963890e-05  5.424370e-06  2.068020e-07   \n",
              "2  0.000080  0.000032  0.000009  2.594656e-06  3.096257e-07  1.102683e-08   \n",
              "3  0.000009  0.000003  0.000001  3.036664e-07  3.115553e-08  9.106774e-10   \n",
              "4  0.000018  0.000011  0.000004  8.104687e-07  4.767324e-08  2.764471e-09   \n",
              "\n",
              "      labels  \n",
              "0    neutral  \n",
              "1    fearful  \n",
              "2  surprised  \n",
              "3      angry  \n",
              "4       calm  \n",
              "\n",
              "[5 rows x 181 columns]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Txnfmsm31k",
        "outputId": "de67b6b0-56ec-4341-cccd-ae7b1c87324b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index([       0,        1,        2,        3,        4,        5,        6,\n",
              "              7,        8,        9,\n",
              "       ...\n",
              "            171,      172,      173,      174,      175,      176,      177,\n",
              "            178,      179, 'labels'],\n",
              "      dtype='object', length=181)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dLqELVKkF5M"
      },
      "source": [
        "**Step 3: Train a Machine Learning Model (SVM & CNN)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "uJJawIIHkH4L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "oWTqBkVCkeVr"
      },
      "outputs": [],
      "source": [
        "data = df.drop('labels', axis=1)\n",
        "labels = df['labels']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr33kIWsISrW",
        "outputId": "933f4eed-1e45-4f8a-bbb0-e2779b049eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 89.24%\n"
          ]
        }
      ],
      "source": [
        "svm_model = SVC(kernel='rbf', C=10, gamma=0.01)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "cpHazrf4o15a"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvvAY6aDo65S"
      },
      "source": [
        "** Convert data to PyTorch tensors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "skK6b3prmcQj"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(pd.get_dummies(y_train).values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(pd.get_dummies(y_test).values, dtype=torch.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOHSPwD9o-QS"
      },
      "source": [
        "**Create DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "KBpQKe2boYFC"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "-kFfKU9_obiz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "0UmPixJkia6Y"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gtQVzu2AofTi"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model\n",
        "class EmotionCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(EmotionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * (input_size // 4), 128)  # Divided by 4 due to two pooling layers\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape: (batch_size, 1, feature_length)\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zXfQ_DX7dit",
        "outputId": "7ca88551-5b17-4c88-f6dc-e0e592cd7f2c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m input_size\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "input_size = X_train.shape[1]\n",
        "input_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZyac0OviE8t",
        "outputId": "95e649f7-8750-4c1a-dd33-bae084e38225"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2304, 180)"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqswVbls_Hg1",
        "outputId": "370897f5-0351-4128-804b-05dc58a7524f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(576, 180)"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTlbBYyj7rQL",
        "outputId": "58673aba-c6a7-41cc-f330-8766d66e4700"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = len(emotion)\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "DXOcja1poh-x"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "input_size = X_train.shape[1]\n",
        "num_classes = len(emotion)\n",
        "model = EmotionCNN(input_size, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "lB0HBZruojvi"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6wYxrwGomDq",
        "outputId": "54b17bb6-3431-46cb-cf7c-e69a9064a8ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmotionCNN(\n",
              "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (fc1): Linear(in_features=5760, out_features=128, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=128, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 144,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYgc26eXoqGa",
        "outputId": "c10908d0-b324-4566-dcfa-5b2c924a764e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Train Loss: 0.2328, Val Loss: 0.5623, Val Acc: 91.67%\n",
            "Epoch [2/10], Train Loss: 0.2061, Val Loss: 0.6166, Val Acc: 92.19%\n",
            "Epoch [3/10], Train Loss: 0.2239, Val Loss: 0.5414, Val Acc: 92.71%\n",
            "Epoch [4/10], Train Loss: 0.2094, Val Loss: 0.4419, Val Acc: 91.84%\n",
            "Epoch [5/10], Train Loss: 0.2177, Val Loss: 0.4377, Val Acc: 92.71%\n",
            "Epoch [6/10], Train Loss: 0.2476, Val Loss: 0.6562, Val Acc: 90.97%\n",
            "Epoch [7/10], Train Loss: 0.2224, Val Loss: 0.6284, Val Acc: 92.36%\n",
            "Epoch [8/10], Train Loss: 0.2185, Val Loss: 0.6464, Val Acc: 91.49%\n",
            "Epoch [9/10], Train Loss: 0.2404, Val Loss: 0.7494, Val Acc: 91.32%\n",
            "Epoch [10/10], Train Loss: 0.2184, Val Loss: 0.7372, Val Acc: 92.71%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.unsqueeze(1).to(device)  # [batch, 1, features]\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, torch.max(labels, 1)[1])  # Convert one-hot to class indices\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.unsqueeze(1).to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, torch.max(labels, 1)[1])\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, true_labels = torch.max(labels.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == true_labels).sum().item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Train Loss: {running_loss/len(train_loader):.4f}, '\n",
        "          f'Val Loss: {val_loss/len(test_loader):.4f}, '\n",
        "          f'Val Acc: {100 * correct/total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "-0tcgBPtosdC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'hassan_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYvFW5XiwZmV",
        "outputId": "d16a93a4-6ffe-4006-b20f-55542e4158c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 92.71%\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.unsqueeze(1).to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, true_labels = torch.max(labels.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == true_labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Assuming you have a DataLoader for your test set\n",
        "evaluate(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9xyucc20D0S"
      },
      "outputs": [],
      "source": [
        "!npm  install localtunnel\n",
        "!streamlit  run app.py & npx localtunnel --port 8501\n",
        "!npm localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOyBldhmB5Jq",
        "outputId": "3ea5cba1-537d-4c70-ed2b-368c49323c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n",
            "Predicted class: 5\n",
            "Predicted label: surprise\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i  in range(18):\n",
        "  sample_tensor = X_test_tensor[0].unsqueeze(0).unsqueeze(1)  \n",
        "\n",
        "  with torch.no_grad():\n",
        "      output = model(sample_tensor)\n",
        "      predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "   \n",
        "      emotion = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral', 'calm']\n",
        "      print(\"Predicted class:\", predicted_class)\n",
        "      print(\"Predicted label:\", emotion[predicted_class])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "sf.write(r\"C:\\Users\\Hassan Ali\\OneDrive\\Desktop\\office\\Task 2\\03-01-03-02-02-01-03.wav\", audio, sample_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Recording...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import sounddevice as sd\n",
        "import scipy.io.wavfile as wav\n",
        "\n",
        "\n",
        "duration = 3 \n",
        "sample_rate = 22050  \n",
        "print(\" Recording...\")\n",
        "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
        "sd.wait()\n",
        "print(\"Done!\")\n",
        "\n",
        "\n",
        "wav.write(\"live_audio.wav\", sample_rate, audio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(file_path):\n",
        "  X, sample_rate=librosa.load(file_path,res_type='kaiser_fast')\n",
        "\n",
        "\n",
        "  mfccs=np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=40).T,axis=0)\n",
        "  chroma=np.mean(librosa.feature.chroma_stft(y=X,sr=sample_rate).T,axis=0)\n",
        "  mel=np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0)\n",
        "\n",
        "  return np.hstack([mfccs,chroma,mel])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class EmotionCNN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(EmotionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * (input_size // 4), 128)  \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1) \n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "input_size = 180\n",
        "num_classes=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmotionCNN(\n",
              "  (conv1): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  (fc1): Linear(in_features=5760, out_features=128, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=128, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "model = EmotionCNN(input_size ,num_classes)  \n",
        "model.load_state_dict(torch.load(\"hassan_model.pth\"))\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "for root, _, files in os.walk('/content/ravdess'):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            parts = file.split('-')\n",
        "            emotion_code = int(parts[2])\n",
        "            emotion_label = emotion.get(emotion_code, 'unknown')\n",
        "\n",
        "            filepath = os.path.join(root, file)\n",
        "\n",
        "            features = extract_features(file_path)\n",
        "            data.append(features)\n",
        "            labels.append(emotion_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "emotion = {\n",
        "    1: 'neutral',\n",
        "    2: 'calm',\n",
        "    3: 'happy',\n",
        "    4: 'sad',\n",
        "    5: 'angry',\n",
        "    6: 'fearful',\n",
        "    7: 'disgust',\n",
        "    8: 'surprised'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recording...\n",
            "Live Prediction: happy\n"
          ]
        }
      ],
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "\n",
        "duration = 7\n",
        "sample_rate = 22050\n",
        "\n",
        "print(\"Recording...\")\n",
        "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
        "sd.wait() \n",
        "\n",
        "\n",
        "audio = np.squeeze(audio)\n",
        "sf.write('temp.wav', audio, sample_rate)\n",
        "features = extract_features('temp.wav')\n",
        "\n",
        "\n",
        "input_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "    predicted_class = torch.argmax(outputs).item()\n",
        "    \n",
        "    if predicted_class >=len(emotion):\n",
        "        print(f\"Invalid emotion please setup your voice brother{predicted_class}\")\n",
        "        \n",
        "    \n",
        "  \n",
        "print(f\"Live Prediction: {emotion[predicted_class]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
